{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04de4b5b-0cdc-4309-88e5-5a43bcd360dd",
   "metadata": {},
   "source": [
    "## Evaluate slick association results on dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d69d24-201e-4932-8723-76349301115a",
   "metadata": {},
   "source": [
    "This expects an input of a GeoJSON file from the slick explorer. This can be generated clicking the `Run All` button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ededde-e06f-46db-848f-52e31051f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b135edcf-66ef-44d1-984d-0ca2ab70e24c",
   "metadata": {},
   "source": [
    "### Load results file along with truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484eb75a-5c9d-4f31-9599-10940ec5104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = 'results_20230413.geojson'\n",
    "results = gpd.read_file(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8156785-2ea4-4d82-9a4e-66eb4ba50a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_file = '/home/k3blu3/datasets/cerulean/slick_truth_year1.csv'\n",
    "truth = pd.read_csv(truth_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096fa238-34d6-4649-9978-7b5531bebc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just grab the columns we need\n",
    "truth = truth[['PID', 'HITL MMSI', 'HITL Confidence', 'Algo MMSI', 'Algo Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feccd4ff-efb5-4d26-bd20-b3c3f49a3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the results and truth on PID\n",
    "results = pd.merge(results, truth, on='PID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d5897-2e9a-4279-8dd0-c86746e8cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode if there are multiple HITL MMSI\n",
    "results = results.assign(truth=results['HITL MMSI'].str.split(',')).explode('truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf8705-2d06-4332-874f-81c78c7c96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of unique samples being evaluated\n",
    "len(pd.unique(results['PID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab1dae-307c-4c9f-b6b6-9312ddecc7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457e6dc-c4de-4712-bcc3-225667accc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up dataframe types\n",
    "results['truth'] = results['truth'].str.strip()\n",
    "results.temporal_score = results.temporal_score.astype(np.float32)\n",
    "results.overlap_score = results.overlap_score.astype(np.float32)\n",
    "results.frechet_dist = results.frechet_dist.astype(np.float32)\n",
    "results.total_score = results.total_score.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dfec6-0d64-4237-8204-03b878421963",
   "metadata": {},
   "source": [
    "### Evaluate results against truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b384a6-2619-4b86-b32b-7bbd4faeb042",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = list()\n",
    "for pid, pid_group in results.groupby('PID'):\n",
    "    # treat each slick independently\n",
    "    for sidx, slick_group in pid_group.groupby('slick_index'):\n",
    "        # we'll take the highest total score\n",
    "        slick_group = slick_group.sort_values('total_score', ascending=False)\n",
    "\n",
    "        entry = dict()\n",
    "        entry['PID'] = slick_group.iloc[0].PID\n",
    "        entry['temporal_score'] = slick_group.iloc[0].temporal_score\n",
    "        entry['overlap_score'] = slick_group.iloc[0].overlap_score\n",
    "        entry['frechet_dist'] = slick_group.iloc[0].frechet_dist\n",
    "        entry['Krishna MMSI'] = slick_group.iloc[0].traj_id\n",
    "        entry['Krishna Score'] = slick_group.iloc[0].total_score\n",
    "        entry['Truth MMSI'] = slick_group.iloc[0]['truth']\n",
    "        entry['Algo MMSI'] = slick_group.iloc[0]['Algo MMSI']\n",
    "\n",
    "        comparisons.append(entry)\n",
    "\n",
    "comparisons = pd.DataFrame(comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b33cb0-0020-48f8-b66e-321a1e9cd32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = list()\n",
    "krishna_score = list()\n",
    "krishna_mmsi = list()\n",
    "algo_mmsi = list()\n",
    "truth_mmsi = list()\n",
    "\n",
    "for p, group in comparisons.groupby('PID'):\n",
    "    for truth in pd.unique(group['Truth MMSI']):\n",
    "        if truth != 'DARK':\n",
    "            pid.append(p)\n",
    "            algo_mmsi.append(group['Algo MMSI'].iloc[0].astype(str))\n",
    "            truth_mmsi.append(truth)\n",
    "            if (group['Krishna MMSI'].astype(str) == truth).any():\n",
    "                row = group[group['Krishna MMSI'].astype(str) == truth]\n",
    "                krishna_mmsi.append(row.iloc[0]['Krishna MMSI'])\n",
    "                krishna_score.append(np.float32(row.iloc[0]['Krishna Score']))\n",
    "            else:\n",
    "                krishna_idx = group['Krishna Score'].astype(np.float32).idxmax()\n",
    "                krishna_mmsi.append(group.loc[krishna_idx]['Krishna MMSI'])\n",
    "                krishna_score.append(np.float32(group.loc[krishna_idx]['Krishna Score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37678bb3-4e59-422d-9515-11cc22ead467",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'pid': pid, \n",
    "                    'krishna_score': krishna_score, \n",
    "                    'krishna_mmsi': krishna_mmsi, \n",
    "                    'algo_mmsi': algo_mmsi, \n",
    "                    'truth_mmsi': truth_mmsi})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add2ff9-2a5b-4f90-a9df-9de393627cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "krishna_correct = res[res['krishna_mmsi'] == res['truth_mmsi']]\n",
    "krishna_incorrect = res[res['krishna_mmsi'] != res['truth_mmsi']]\n",
    "algo_correct = res[res['algo_mmsi'] == res['truth_mmsi']]\n",
    "algo_incorrect = res[res['algo_mmsi'] != res['truth_mmsi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32681fa4-12ee-4b1d-80a1-db6ad1eabc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "krishna_pct = 100 * len(krishna_correct) / len(res)\n",
    "algo_pct = 100 * len(algo_correct) / len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca559edf-4241-436c-942c-35cf36785d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(krishna_pct)\n",
    "print(algo_pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa43510f-4931-4eff-b727-b0452545b223",
   "metadata": {},
   "source": [
    "### Quick plot of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c006fb-7945-407b-a982-2e0c265eb6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=200, figsize=(10, 5))\n",
    "plt.style.use('ggplot')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(krishna_correct.krishna_score, color='red', alpha=0.7)\n",
    "plt.title('Correct Matches')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Counts')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(krishna_incorrect.krishna_score, color='blue', alpha=0.7)\n",
    "plt.title('Incorrect Matches')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Counts')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldev",
   "language": "python",
   "name": "mldev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
